# Unsupervised Representation

Bird’s eye view

<img src="https://ik.imagekit.io/haochen/Typora/image-20220803225535807.png" alt="image-20220803225535807" style="zoom:50%;" />

最大化互信息

gap persist

**Untangling Representation**

![image-20220803230336108](https://ik.imagekit.io/haochen/Typora/image-20220803230336108.png)

**Infomation Bottleneck**

 ![image-20220803230543821](https://ik.imagekit.io/haochen/Typora/image-20220803230543821.png)

discard

### Invariance and Equivariance

![image-20220803230632057](https://ik.imagekit.io/haochen/Typora/image-20220803230632057.png)



### Equivariance and Dientanglement

![image-20220804150918370](https://ik.imagekit.io/haochen/Typora/image-20220804150918370.png)



<img src="https://ik.imagekit.io/haochen/Typora/image-20220804151059873.png" alt="image-20220804151059873" style="zoom:50%;" />

Can transform feature space into several subspace…

### Evaluating Representation

<img src="https://ik.imagekit.io/haochen/Typora/image-20220804151155028.png" alt="image-20220804151155028" style="zoom:33%;" />



<img src="https://ik.imagekit.io/haochen/Typora/image-20220804151819094.png" alt="image-20220804151819094" style="zoom:50%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220804151915718.png" alt="image-20220804151915718" style="zoom:50%;" />

Hence, given the prominent past and potential future road of good representation in ML.

### Techniques

<img src="https://ik.imagekit.io/haochen/Typora/image-20220804152202990.png" alt="image-20220804152202990" style="zoom:50%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220804152652249.png" alt="image-20220804152652249" style="zoom:30%;" />

![image-20220804154716589](https://ik.imagekit.io/haochen/Typora/image-20220804154716589.png)

![image-20220804154924533](https://ik.imagekit.io/haochen/Typora/image-20220804154924533.png)

![image-20220804155004864](https://ik.imagekit.io/haochen/Typora/image-20220804155004864.png)

![image-20220804155022437](https://ik.imagekit.io/haochen/Typora/image-20220804155022437.png)

![image-20220804155205218](https://ik.imagekit.io/haochen/Typora/image-20220804155205218.png)

![image-20220804155236237](https://ik.imagekit.io/haochen/Typora/image-20220804155236237.png)

### beta-vae

<img src="https://ik.imagekit.io/haochen/Typora/image-20220804155250240.png" alt="image-20220804155250240" style="zoom:30%;" />

### ConvDraw

![image-20220804155441052](https://ik.imagekit.io/haochen/Typora/image-20220804155441052.png)

![image-20220804155448544](https://ik.imagekit.io/haochen/Typora/image-20220804155448544.png)

### Layered Model

![image-20220804155532053](https://ik.imagekit.io/haochen/Typora/image-20220804155532053.png)

### MONET

![image-20220804160000987](https://ik.imagekit.io/haochen/Typora/image-20220804160000987.png)

### GQN

![image-20220804160112460](https://ik.imagekit.io/haochen/Typora/image-20220804160112460.png)

### Discrete

![image-20220804160408270](https://ik.imagekit.io/haochen/Typora/image-20220804160408270.png)

But this **X** likelihood-based loss will introduce blurry

**BigBigGan**

<img src="https://ik.imagekit.io/haochen/Typora/image-20220805150319131.png" alt="image-20220805150319131" style="zoom:50%;" />

**Image and latent should match** 



### GPT

![image-20220805150457218](https://ik.imagekit.io/haochen/Typora/image-20220805150457218.png)

### Contrastive Learning

![image-20220805150602688](https://ik.imagekit.io/haochen/Typora/image-20220805150602688.png)

encode the world we live in





### CPC

maximize mutural information

![image-20220805151319510](https://ik.imagekit.io/haochen/Typora/image-20220805151319510.png)

![image-20220805151332229](https://ik.imagekit.io/haochen/Typora/image-20220805151332229.png)

### SimCLR

![image-20220805151444072](https://ik.imagekit.io/haochen/Typora/image-20220805151444072.png)

![image-20220805151508942](https://ik.imagekit.io/haochen/Typora/image-20220805151508942.png)

Classification loss to encode 

this kind of temporal or spatial consistency into representation



### SSL

We encode the information that we expect in our representation

<img src="https://ik.imagekit.io/haochen/Typora/image-20220805151806316.png" alt="image-20220805151806316" style="zoom:25%;" />

Such as colorization

![image-20220805151821346](https://ik.imagekit.io/haochen/Typora/image-20220805151821346.png)

#### Bert

![image-20220805152028821](https://ik.imagekit.io/haochen/Typora/image-20220805152028821.png)

Mask, Global and Local sturcture

![image-20220805152116289](https://ik.imagekit.io/haochen/Typora/image-20220805152116289.png)

<img src="https://ik.imagekit.io/haochen/Typora/image-20220805152126623.png" alt="image-20220805152126623" style="zoom:33%;" />

Task Design

![image-20220805152143907](https://ik.imagekit.io/haochen/Typora/image-20220805152143907.png)

### Next

![image-20220805152326305](https://ik.imagekit.io/haochen/Typora/image-20220805152326305.png)