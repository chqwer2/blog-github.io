# Reinforce Learning

Serene Yueng

![image-20211102082916019](https://chqwer2.github.io/img/Typora/image-20211102082916019.png)

![image-20211102082949758](https://chqwer2.github.io/img/Typora/image-20211102082949758.png)

![image-20211102083024543](https://chqwer2.github.io/img/Typora/image-20211102083024543.png)

![image-20211102083152751](https://chqwer2.github.io/img/Typora/image-20211102083152751.png)

## Markov Decision Process

![image-20211102083319395](https://chqwer2.github.io/img/Typora/image-20211102083319395.png)

![image-20211102083637057](https://chqwer2.github.io/img/Typora/image-20211102083637057.png)

![image-20211102083748019](https://chqwer2.github.io/img/Typora/image-20211102083748019.png)

![image-20211102083843388](https://chqwer2.github.io/img/Typora/image-20211102083843388.png)

![image-20211102084309970](https://chqwer2.github.io/img/Typora/image-20211102084309970.png)

Trajectory 轨迹

![image-20211102084511092](https://chqwer2.github.io/img/Typora/image-20211102084511092.png)

![image-20211102084729230](https://chqwer2.github.io/img/Typora/image-20211102084729230.png)

![image-20211102093247922](https://chqwer2.github.io/img/Typora/image-20211102093247922.png)

## Q-Learning

![image-20211102093353140](https://chqwer2.github.io/img/Typora/image-20211102093353140.png)

![image-20211102093502341](https://chqwer2.github.io/img/Typora/image-20211102093502341.png)

![image-20211102093605993](https://chqwer2.github.io/img/Typora/image-20211102093605993.png)

![image-20211102093659385](https://chqwer2.github.io/img/Typora/image-20211102093659385.png)

![image-20211102094103992](https://chqwer2.github.io/img/Typora/image-20211102094103992.png)

![image-20211102094211734](https://chqwer2.github.io/img/Typora/image-20211102094211734.png)

## Policy Gradient

![image-20211102094714997](https://chqwer2.github.io/img/Typora/image-20211102094714997.png)

![image-20211102094929216](https://chqwer2.github.io/img/Typora/image-20211102094929216.png)

![image-20211102095055262](https://chqwer2.github.io/img/Typora/image-20211102095055262.png)

Monte Carlo Sampling

![image-20211102095317220](https://chqwer2.github.io/img/Typora/image-20211102095317220.png)

![image-20211102095503724](https://chqwer2.github.io/img/Typora/image-20211102095503724.png)

![image-20211102100442788](https://chqwer2.github.io/img/Typora/image-20211102100442788.png)

![image-20211102100527576](https://chqwer2.github.io/img/Typora/image-20211102100527576.png)

![image-20211102102307856](https://chqwer2.github.io/img/Typora/image-20211102102307856.png)

Don't know Q and V?

![image-20211102102334449](https://chqwer2.github.io/img/Typora/image-20211102102334449.png)

<img src="https://chqwer2.github.io/img/Typora/image-20211102102623322.png" alt="image-20211102102623322" style="zoom:70%;" />

![image-20211102102936908](https://chqwer2.github.io/img/Typora/image-20211102102936908.png)

![image-20211102103237181](https://chqwer2.github.io/img/Typora/image-20211102103237181.png)

![image-20211102103340172](https://chqwer2.github.io/img/Typora/image-20211102103340172.png)

![image-20211102103633337](https://chqwer2.github.io/img/Typora/image-20211102103633337.png)

1. First SL train a networks from board state to action to take
2. Policy Gradient playing against itself
3. A value network and Monte Carlo Tree Search

![image-20211102104120209](https://chqwer2.github.io/img/Typora/image-20211102104120209.png)