# Correlation

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522160304195.png" alt="image-20220522160304195" style="zoom:33%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522155358766.png" alt="image-20220522155358766" style="zoom:33%;" />

**Why devided by std?**

For example, all the sons were shifted an inch taller,

nothing would change about the association between fathers and sons

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522155759534.png" alt="image-20220522155759534" style="zoom:33%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522155947718.png" alt="image-20220522155947718" style="zoom:25%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522155957105.png" alt="image-20220522155957105" style="zoom:25%;" />

We can see some relation in them, but $r=0$, why?

Because correlation only measure **linear Relationship**

#### Covariance

![image-20220522161910229](https://ik.imagekit.io/haochen/Typora/image-20220522161910229.png)

For Regression

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522162610134.png" alt="image-20220522162610134" style="zoom:30%;" />

What it does?

How Correlation to Regression?

<img src="https://ik.imagekit.io/haochen/Typora/image-20220522162813909.png" alt="image-20220522162813909" style="zoom:33%;" />



![image-20220527162833273](https://ik.imagekit.io/haochen/Typora/image-20220527162833273.png)

![image-20220527162842611](https://ik.imagekit.io/haochen/Typora/image-20220527162842611.png)

### Derivation of estimator

![image-20220527173100812](https://ik.imagekit.io/haochen/Typora/image-20220527173100812.png)

![image-20220527173211928](https://ik.imagekit.io/haochen/Typora/image-20220527173211928.png)

Calculate the derivative

![image-20220527173327264](https://ik.imagekit.io/haochen/Typora/image-20220527173327264.png)



![image-20220527174804989](https://ik.imagekit.io/haochen/Typora/image-20220527174804989.png)

![image-20220527180740236](https://ik.imagekit.io/haochen/Typora/image-20220527180740236.png)

![image-20220527182950379](https://ik.imagekit.io/haochen/Typora/image-20220527182950379.png)

![image-20220527183021551](https://ik.imagekit.io/haochen/Typora/image-20220527183021551.png)

**Detailed Derivation **- No

![image-20220527183120054](https://ik.imagekit.io/haochen/Typora/image-20220527183120054.png)





### 

### Multidimensional convexity and local optimization

![image-20220531173732551](https://ik.imagekit.io/haochen/Typora/image-20220531173732551.png)

Hessian example

<img src="https://ik.imagekit.io/haochen/Typora/image-20220531173806682.png" alt="image-20220531173806682" style="zoom:50%;" />

### Newton's method of minimization for high rank equation

![image-20220531174530543](https://ik.imagekit.io/haochen/Typora/image-20220531174530543.png)

![image-20220531174604771](https://ik.imagekit.io/haochen/Typora/image-20220531174604771.png)

![image-20220531174622680](https://ik.imagekit.io/haochen/Typora/image-20220531174622680.png)

### For Newton GD

![image-20220531174913184](https://ik.imagekit.io/haochen/Typora/image-20220531174913184.png)