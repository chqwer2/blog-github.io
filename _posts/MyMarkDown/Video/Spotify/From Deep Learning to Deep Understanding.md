# From Deep Learning to Deep Understanding

![image-20220730152018355](https://ik.imagekit.io/haochen/Typora/image-20220730152018355.png)

I would say, we are not making so much progress in terms of understanding despite this amazing progress

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730152255887.png" alt="image-20220730152255887" style="zoom:25%;" />

In a way, we are probably at the stage of lacking of intelligence, despite the DL.

We have to go back to look at, what did we really learn?

Knowledge representation or cognitive model or reasoning.

It did a great job in general

shows the 



![image-20220730153503489](https://ik.imagekit.io/haochen/Typora/image-20220730153503489.png)

And they really shows the limits of so called Deep Learning. 

All focus on statistics pattern

language understanding… (learns that)

![image-20220730153824127](https://ik.imagekit.io/haochen/Typora/image-20220730153824127.png)

Noisy student.

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730154226300.png" alt="image-20220730154226300" style="zoom:25%;" />

Also <the decade of AI>

![image-20220730154307429](https://ik.imagekit.io/haochen/Typora/image-20220730154307429.png)

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730154344332.png" alt="image-20220730154344332" style="zoom:33%;" />

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730154525274.png" alt="image-20220730154525274" style="zoom:33%;" />

What can we really do you know what are the research directions that we could possibly pursue.

Especially I would say you need a turn.

I certainly believe that that we have some amazing opportunities the term towards understanding, for example, that they know the result of ML, machine learning, should not be just a set of classifiers windfall you should ask for the reverse aging that continues to learn skills, knowledge, you know, by practicing and the by exploring in the rest of my talk. 



![image-20220730155000555](https://ik.imagekit.io/haochen/Typora/image-20220730155000555.png)

### Important Papers

![image-20220730155103906](https://ik.imagekit.io/haochen/Typora/image-20220730155103906.png)

The perfect light in the figure eight here, and you have all those sample points in a perfectly sampled from those three representations to play for the practice you often see have some noises, and the lighting in B you see some noise, and the impact is you also see some kind of outliers, which is even more annoying. And in this case if you can see you have those red points, you know, showing that you know that's the thing. 

![image-20220730155540731](https://ik.imagekit.io/haochen/Typora/image-20220730155540731.png)

to low-dimensional submanifolds

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730155653244.png" alt="image-20220730155653244" style="zoom:25%;" />

task-dependent..

**Learn to compress and compress to learn**？ where 

![image-20220730155839376](https://ik.imagekit.io/haochen/Typora/image-20220730155839376.png)

![image-20220730155906090](https://ik.imagekit.io/haochen/Typora/image-20220730155906090.png)

Using Compress

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730160020278.png" alt="image-20220730160020278" style="zoom:25%;" />

![image-20220730160105708](https://ik.imagekit.io/haochen/Typora/image-20220730160105708.png)

![image-20220730160125089](https://ik.imagekit.io/haochen/Typora/image-20220730160125089.png)

![image-20220730160411716](https://ik.imagekit.io/haochen/Typora/image-20220730160411716.png)

#### Symbolic 

![image-20220730160437012](https://ik.imagekit.io/haochen/Typora/image-20220730160437012.png)

From classification，

![image-20220730162107703](https://ik.imagekit.io/haochen/Typora/image-20220730162107703.png)

If  you have a model, the task oriented example,

it just not right.

So basically, the problem we faced, is that, we want to do sth

**What is grounding here?**

![image-20220730162657823](https://ik.imagekit.io/haochen/Typora/image-20220730162657823.png)

![image-20220730162852303](https://ik.imagekit.io/haochen/Typora/image-20220730162852303.png)

### Contrasive Learning

![image-20220730163142981](https://ik.imagekit.io/haochen/Typora/image-20220730163142981.png)

![image-20220730163233347](https://ik.imagekit.io/haochen/Typora/image-20220730163233347.png)

##### Grounded responses !!!

like background

### SOLOIST (W/ Grounds)

<img src="https://ik.imagekit.io/haochen/Typora/image-20220730163521274.png" alt="image-20220730163521274" style="zoom:25%;" />

So time is now, you know, forced to move to, to really focus on, you know, merely to create research in terms of you know, understanding, we should move to deep understanding from deep learning. In a way, you know what we're trying to do is actually you know we are working towards the robust AI, so that we can statistically geometrically understand something semantically really explain, you know, what AI is really doing. 



That they don’t understand text anything, anywhere near human level.

